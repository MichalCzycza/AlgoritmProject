Algorytm wyszukujący ilośc wystąpień słow w pliku wejściowym (indkesowanie dokumentów - dopisanie do indeksu słowo IT pojawiło się x razy - rozbudowanie indeksów dotyczących słów)
Np. daj mi 10 dokumentów związanych z IT (Trzeba utworzyć inverted indeksy)

Indkesowanie i wyszukiwanie słów
wyświetlenie n dokumentów zgodnych z danym profilem

Ważna jest frekwencja występowania wyszukiwanych słów kluczowych. Liczba wystąpień danego słowa rzutuje na zgodność tekstu z wyszukiwanym kontekstem w ten sposób,
że jeśli słowo wystąpiło n razy, to w odpowiednim miejscu wektora zgodności ma się pojawić wartość log10(n).

profil wystąpienia  wektor
armia       10      -> 1,00
armata       5      -> 0,69
generał      0      -> 0,00
major       12      -> 1,08
                    -----
zgodność            0,6925

Firma CyberData poprosiła Ciebie jako pracownika wydziału algorytmiki o przygotowanie i implementacje własną wyszukiwarki słuzącej do gromadzenia
i wyszukiwnaia dokumentów pochodzących z różnych źródeł i dotyczących rozmaitej tematyki (kryptografia, elektronika, dokumenty ekonomiczne itp.)
Nasze algorytmy mają ułatwić i przyspieszyć zapoznanie się przez pracowników firmy z materiałamy relewantnymi względem ich specjalności i stanowiska pracy.
Dla każdej tematyki w systemie przechowywany jest jej profil w postaci słów kluczowych (np. dla kryptografii są to słowa szyfrowanie, DSA , AES, TLS, SSL).
Przykładowo pracownik działu inżynierii informatycznej będzie zaintersowany materiałami z dziedziny informatyki, szyfrowania, baz danych i języków programowania 
(ogólnie wszystkich materiałów zgodnych z profilem IT). Dział programistyczny dostarczył "stop listę" służacą do eliminowania słow nieznaczących, bazę profili
z konkretnych dziedzin, zbioru dokumentów testowych oraz słownik odmian dla języka polskiego. Równocześnie ustalił strukturę metod w których powinniśmy
dokonac implementacji głownych funckjonalność. Wszystkie algorytmy oraz struktury danych będą zaimplemntowane własnoręcznie i powinny znajdować się w naszych z góry ustalonych
metodach. Szef działu programistyczne, ze względów technicznych, nie dopuszcza do używania zaimportowanych klas kolekcji (np. List, Map, Set) jak i algotymów wyszukiwania sortowania itp.
Premiowane będzie przez wydział informatyki zastosowanie algorytmów o niskiej złożoności obliczeniowej np. własna implemntacja HashMapy.

W projekcie należy zaimplementować metody w klasach MDictionary (odpowiedzialna za przechowywanie słownika z mechanizmem haszowania) oraz SearchEngine.
W obu klasach nie wolno zmieniać nazw metod, które zostały w nich już zawarte. Wolno natomiast tworzyć własne metody pomocnicze ale nie klasy.
Nie wolno dokonywać żadnych zmian w klasie SearchApplication (klasa aplikacji).




















-----------------------------------------------------------
odwrócony indeks i haszowanie

-----------------------------------------------------------

-----------------------------------------------------------

- Mająć dokument to po pierwsze musimy rozbić dokument na słowa poprzez parsowanie (bez analizy morfologicznej), które nie może być case sensitive.
(Zakładamy, że posiadamy słównik słów nieistotnych, które nie są brane przy indkesowaniu - tak zwana stop lista słowa jak są by i do przy itp.)   
- przy pomocy biblioteki MorfologyTool należy zamienić słowa na formę główną (krowy krowa, koty kot, jedzą jeść) 
- Przy pomocy słownika zbudowanego przez studenta (hashtable / hashmap) zliczamy frekwencje słów w dokumencie
- Zapisanie w plikach indeksowych frekwencji słowo kluczowe oraz nazwy dokumentu (dla każdego słowa inny plik indeksowy) -> O (liczba słów w dokumencie)-  maks 3p. / half 1.5p
* Zapisanie w pliku inverted index o takiej samej nazwie jak analizowany plik frekwencji słów, które w nim wystąpiły. (np. sukcesy szyfrowania.idx -  ile słów kluczowych ile razy)
- Zwrocenie dokumentów zawierających podane słowo - funkcja getDocsContainingWord(String word) -> O(docs*words) - maks 1p.
- Zwrocenie dokumentów zawierających podane słowa - funkcja getDocsContainingWords(String[] words) -> O(docs*words) - maks 3p. / half 2p.
- Zwrócenie użytkownikowi n dokumentów zawierających najwięcej słów z podanej listy - funkcja getDocsWithMaxMatchingWords(int n, String[] words) -> O(docs*words) + sortowanie O(docs) - maks 6 p. / half 3p.
- Zwrócenie n dokumentów z największą zgodnościa z wybranym profilem - funkcja getDocsClosestToProfile(int n, String[] profile) -> O(docs * profile.length) -> maks 7p. / half 3p.
+ Zwolnienie za na 5 -> ostatnie 2 punkty na maks punktów oraz rozwiązanie problemu pracy na pojęciach składających się z dwóch słów (np. baza danych) jest propozycją zwolnienia z egzaminu z oceną 5 lub 4,5 za egzamin -> O(n)  